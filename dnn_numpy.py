"""
a dnn model written by numpy & pandas
tian yan
uestc
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['lines.linewidth'] = 2

global layer_number


def init_data(train_set_from_excel, test_set_from_excel):
    """
    load the train & test data from Excel chart
    :param train_set_from_excel: the dataset of train
    :param test_set_from_excel: the dataset of test
    :return: transposed & normalized train_character,test_character,train_label,test_label
    """
    train_set_character = np.array(train_set_from_excel[["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K"]])
    test_set_character = np.array(test_set_from_excel[["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K"]])
    train_set_output = np.array(train_set_from_excel[["EH"]])
    test_set_output = np.array(test_set_from_excel[["EH"]])
    row_train_set = train_set_character.shape[0]
    col_train_set = train_set_character.shape[1]
    row_test_set = test_set_character.shape[0]
    col_test_set = test_set_character.shape[1]
    """
    transpose & normalization insure that all matrix's shape[0] are the character number
    """
    train_characteristic = np.zeros((col_train_set, row_train_set))
    test_characteristic = np.zeros((col_test_set, row_test_set))
    for i in range(col_test_set):
        train_characteristic[i, :] = (train_set_character.T[i, :] - np.min(train_set_character.T[i, :])) / (
                np.max(train_set_character.T[i, :]) - np.min(train_set_character.T[i, :]))
        test_characteristic[i, :] = (test_set_character.T[i, :] - np.min(test_set_character.T[i, :])) / (
                np.max(test_set_character.T[i, :]) - np.min(test_set_character.T[i, :]))
    train_put_out = np.zeros((1, row_train_set))
    test_put_out = np.zeros((1, row_test_set))
    train_put_out[0, :] = (train_set_output.T[0, :] - np.min(train_set_output.T[0, :])) / (
            np.max(train_set_output.T[0, :]) - np.min(train_set_output.T[0, :]))
    test_put_out[0, :] = (test_set_output.T[0, :] - np.min(test_set_output.T[0, :])) / (
            np.max(test_set_output.T[0, :]) - np.min(test_set_output.T[0, :]))
    return train_characteristic, test_characteristic, train_put_out, test_put_out


def relu(line):
    """
    active function of this model
    :param line: line funtion wx+b
    :return: the active output
    """
    active = np.maximum(0, line)
    return active


def init_parameter(initial_character):
    """
    initialization of parameter of the line function wx+b: w & b matrix
    values of w & b matrix are generated by random
    :param initial_character:initialed train_set_character
    :return:initialized parameter & layer number of the dnn
    """
    dim = [10, 30, 20, 10, 5, 1]
    layer_num = len(dim)
    param_init = {}
    param_init["w1"] = np.random.rand(dim[0], initial_character.shape[0]) / np.sqrt(initial_character.shape[0])
    param_init["b1"] = np.random.rand(dim[0], 1) * 0.1
    for i in range(1, layer_num):
        param_init["w" + str(i + 1)] = np.random.rand(dim[i], dim[i - 1]) / np.sqrt(initial_character.shape[0])
        param_init["b" + str(i + 1)] = np.random.rand(dim[i], 1) * 0.1
    return param_init, layer_num


def forward_propagation(param_forward, iteration_character_forward):
    """
    iteration function of forward propagation to generate the line function & active function
    :param param_forward:last iteration generated parameters
    :param iteration_character_forward:train/test character same as the initial
    :return:generated line & active function used for backward propagation & grad down compute
    """
    varia_forward = {}
    varia_forward["line1"] = np.dot(param_forward["w1"], iteration_character_forward) + param_forward["b1"]
    varia_forward["active1"] = relu(varia_forward["line1"])
    for i in range(1, layer_number):
        varia_forward["line" + str(i + 1)] = np.dot(param_forward["w" + str(i + 1)], varia_forward["line" + str(i)]) + \
                                             param_forward["b" + str(i + 1)]
        varia_forward["active" + str(i + 1)] = relu(varia_forward["line" + str(i + 1)])
    return varia_forward


def back_propagation(param_back, varia_back, iteration_character_backward, iteration_label_backward):
    """
    iteration function of backward propagation to generate grad
    :param param_back: last iteration forward propagation parameter
    :param varia_back: last iteration forward propagation linear & active function
    :param iteration_character_backward: backward propagation to the input character
    :param iteration_label_backward: output & first data of backward propagation
    :return: grad matrix of linear,active,weight ,bias
    """
    num = iteration_character_backward.shape[1]
    grad = {}
    grad["dl" + str(layer_number)] = (varia_back["active" + str(layer_number)] - iteration_label_backward) / num
    for i in range(layer_number, 1, -1):
        grad["dw" + str(i)] = np.dot(grad["dl" + str(i)], varia_back["active" + str(i - 1)].T)
        grad["db" + str(i)] = np.sum(grad["dl" + str(i)])
        grad["dl" + str(i - 1)] = np.dot(param_back["w" + str(i)].T, grad["dl" + str(i)])
    grad["dw1"] = np.dot(grad["dl1"], iteration_character_backward.T)
    grad["db1"] = np.sum(grad["dl1"], axis=1, keepdims=True)
    return grad


def loss_function(varia_l, iteration_label_loss, layer_l):
    """
    generate the loss function
    :param varia_l: linear & active function matrix
    :param iteration_label_loss: output label
    :param layer_l: layer number of dnn
    :return: loss funtion
    """
    loss = np.sum((iteration_label_loss - varia_l["active" + str(layer_l)]) ** 2) / (2 * iteration_label_loss.shape[1])
    return loss


def grad_down(param_grad, iter_coefficient, grad_g):
    """
    use grad down algorithm to search the best weight and bias of dnn
    :param param_grad: weight and bias matrix
    :param iter_coefficient: coefficient of iteration steps
    :param grad_g: grad matrix generated from backward propagation
    :return: parameter of weight and bias after grad down iteration
    """
    for i in range(1, layer_number + 1):
        param_grad["w" + str(i)] = param_grad["w" + str(i)] - iter_coefficient * grad_g["dw" + str(i)]
        param_grad["b" + str(i)] = param_grad["b" + str(i)] - iter_coefficient * grad_g["db" + str(i)]
    return param_grad


def my_dnn_train(train_dnn_character, train_dnn_label, iter_times, iter_coefficient, layer_d):
    """
    integrate all part functions to train the dnn and show every 100 iterations
    :param train_dnn_character: input the train character
    :param train_dnn_label: the output label
    :param iter_times: times of iteration
    :param iter_coefficient: coefficient of iteration steps
    :param layer_d: layer number of dnn
    :return: trained parameter of weight and bias,lost_f to draw loss function's iteration
    """
    param_dnn, layer_numb = init_parameter(train_dnn_character)
    lost_f = []
    for i in range(1, iter_times + 1):
        varia_dnn = forward_propagation(param_dnn, train_dnn_character)
        grad_dnn = back_propagation(param_dnn, varia_dnn, train_dnn_character, train_dnn_label)
        param_dnn = grad_down(param_dnn, iter_coefficient, grad_dnn)
        loss = loss_function(varia_dnn, train_dnn_label, layer_d)
        if i % 100 == 0 and i != 0:
            print("第{}次迭代损失函数的值为：{}".format(i, loss))
            lost_f.append(loss)
    return param_dnn, lost_f


def my_dnn_predict(character_train, label_train, character_test, label_test, param_predict):
    """
    show the accuracy of train and predict
    :param character_train:original dataset of train character
    :param label_train:original dataset of train label
    :param character_test:original dataset of test character
    :param label_test:original dataset of test label
    :param param_predict:trained parameter of weight and bias
    :return:matrix of train and test predicted output  label
    """
    varia_train = forward_propagation(param_predict, character_train)
    label_predict_train = varia_train["active" + str(layer_number)]
    varia_test = forward_propagation(param_predict, character_test)
    label_predict_test = varia_test["active" + str(layer_number)]
    print("训练集准确率为:{}%".format((100 - np.mean(np.abs(label_predict_train - label_train)) * 100)))
    print("测试集准确率为:{}%".format((100 - np.mean(np.abs(label_predict_test - label_test)) * 100)))
    return label_predict_train, label_predict_test


if __name__ == '__main__':
    train_set_from_Excel = pd.read_excel('D:/TRAINNCL/TRAIN2/DNN_Test/dataset/train.xlsx')
    test_set_from_Excel = pd.read_excel('D:/TRAINNCL/TRAIN2/DNN_Test/dataset/test.xlsx')  # load the dataset
    iteration_times = 2000
    iteration_coefficient = 0.001  # set iteration times and coefficient
    train_character, test_character, train_output, test_output = init_data(train_set_from_Excel, test_set_from_Excel)
    param, layer_number = init_parameter(train_character)  # initial dataset and parameter
    varia = forward_propagation(param, train_character)
    grad = back_propagation(param, varia, train_character, train_output)
    parameter_g = grad_down(param, iteration_coefficient, grad)  # generate dnn input parameter
    para_d, lost = my_dnn_train(train_character, train_output, iteration_times, iteration_coefficient, layer_number)
    Y_train_predict, Y_test_predict = my_dnn_predict(train_character, train_output, test_character, test_output, para_d)
    plt.plot(lost)
    plt.title('损失函数随迭代次数变化图')
    plt.xlabel('迭代次数')
    plt.ylabel('损失函数值')
    plt.show()  # draw loss function's change of iteration
